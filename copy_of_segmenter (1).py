# -*- coding: utf-8 -*-
"""Copy of Segmenter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T5XU2Qe1J1ftTa0NgAIJ1IGMPhBsc-_2
"""

!pip install keras-tuner

pip install protobuf==3.20.*

from skimage.draw import polygon
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import cv2
import keras
from keras.models import *
from keras.layers import *
from keras import layers
import tensorflow as tf
import os
import keras_tuner as kt
import glob

batch_size = 64
image_size = (224,224,3)
epochs = 10
learning_rate = 1e-4
path = r""
num_classes = 2

metadata = pd.read_csv(os.path.join(path,"FileList.csv"))
metadata.drop(axis=0,index=np.arange(10025,10030),inplace=True)

vols = pd.read_csv("VolumeTracings.csv")

vols[vols["FileName"] == "0X234005774F4CB5CD"]
metadata[metadata["FileName"] == "0X234005774F4CB5CD"]

import keras.backend as K

def get_intersection_and_sums(prediction,target):
    p = tf.cast(K.batch_flatten(prediction),tf.float32)
    t = tf.cast(K.batch_flatten(K.argmax(target,axis=-1)),tf.float32)
    print(p.shape,t.shape,sep=" ")
    intersection = K.sum(p * t,axis=-1)
    output_sum = K.sum(p,axis=-1)
    target_sum = K.sum(t,axis=-1)
    return intersection, output_sum, target_sum

def dice_coef(prediction, target):
    intersection, output_sum, target_sum = get_intersection_and_sums(prediction, target)
    dice = 2 * intersection / (output_sum + target_sum)
    return dice

def convolution_block(
    block_input,
    num_filters=256,
    kernel_size=3,
    dilation_rate=1,
    padding="same",
    use_bias=False,
):
    x = layers.Conv2D(
        num_filters,
        kernel_size=kernel_size,
        dilation_rate=dilation_rate,
        padding="same",
        use_bias=use_bias,
        kernel_initializer=keras.initializers.HeNormal(),
    )(block_input)
    x = layers.BatchNormalization()(x)
    return tf.nn.relu(x)


def DilatedSpatialPyramidPooling(dspp_input,hp):
    dims = dspp_input.shape
    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)
    x = convolution_block(x, kernel_size=1, use_bias=True)
    out_pool = layers.UpSampling2D(
        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation="bilinear",
    )(x)

    dilation_rate = hp.Int("dilation_rate",min_value=2,max_value=12)

    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)
    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=dilation_rate)
    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=dilation_rate*2)
    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=dilation_rate*3)

    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])
    output = convolution_block(x, kernel_size=1)
    return output

def DeeplabV3Plus1(hp):
    image_size = 224
    num_classes = 2
    model_input = keras.Input(shape=(image_size, image_size, 3))
    resnet50 = keras.applications.ResNet50(
        weights="imagenet", include_top=False, input_tensor=model_input
    )
    trainable_layers = hp.Int("trainable_layers",min_value=0,max_value=len(resnet50.layers))
    for idx,layer in enumerate(reversed(resnet50.layers)):
        if idx == trainable_layers:
            break
        layer.trainable = True
    x = resnet50.get_layer("conv3_block3_2_relu").output
    x = DilatedSpatialPyramidPooling(x,hp)

    input_a = layers.UpSampling2D(
        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),
        interpolation="bilinear",
    )(x)
    input_b = resnet50.get_layer("conv2_block3_2_relu").output
    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)

    x = layers.Concatenate(axis=-1)([input_a, input_b])
    x = convolution_block(x)
    x = convolution_block(x)
    x = layers.UpSampling2D(
        size=(image_size // x.shape[1], image_size // x.shape[2]),
        interpolation="bilinear",
    )(x)
    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding="same")(x)
    model = keras.Model(inputs=model_input, outputs=model_output)
    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,epsilon=1e-8),metrics=["accuracy",dice_coef])
    return model

def load_avi(path, max_frames=0):
    capture = cv2.VideoCapture("Videos/" + path + ".avi")
    frames = []
    try:
        while True:
            ret, frame = capture.read()
            if not ret:
                break
            frame = frame[:,:,[2,1,0]]
            frames.append(frame)

            if len(frames) == max_frames:
                break
    finally:
        capture.release()
    for i in range(len(frames)):
        frame = frames[i]
        frames[i] = cv2.resize(frame,dsize=image_size[:2],interpolation=cv2.INTER_CUBIC)
    return np.array(frames) / 255.

def sequentialize(frame):
    coords1 = frame[["X1","Y1"]].values
    coords2 = np.flip(frame[["X2","Y2"]].iloc[1:].values,axis=0)
    bottom_coord = frame[["X2","Y2"]].iloc[0].values
    coords = np.vstack([coords1,bottom_coord,coords2])
    return coords

def yield_segmentation(filename):
    frame = vols.loc[(vols["FileName"] == filename + ".avi"),:]
    try:
        mask = frame["Frame"] == frame["Frame"].iloc[0]
    except:
        print(frame,filename)
    first = frame[mask]
    num1 = first["Frame"].iloc[0]
    second = frame[~mask]
    num2 = second["Frame"].iloc[0]
    coords_first = sequentialize(first)
    coords_second = sequentialize(second)
    r1,c1 = polygon(coords_first[:,1],coords_first[:,0])
    r1,c1 = np.clip(r1,0,111),np.clip(c1,0,111)
    r2,c2 = polygon(coords_second[:,1],coords_second[:,0])
    r2,c2 = np.clip(r2,0,111),np.clip(c2,0,111)
    seg1 = np.zeros((112,112),dtype=np.uint8)
    seg1[r1,c1] = 1
    seg1 = cv2.resize(seg1,dsize=image_size[:2],interpolation=cv2.INTER_CUBIC)
    seg2 = np.zeros((112,112),dtype=np.uint8)
    seg2[r2,c2] = 1
    seg2 = cv2.resize(seg2,dsize=image_size[:2],interpolation=cv2.INTER_CUBIC)
    video = load_avi(filename)
    return (video[num1],seg1),(video[num2],seg2)

def prepare_data(df,root_dir):
    video_paths = df["FileName"].values.tolist()
    num_samples = len(df)*2
    image = np.zeros(shape=(num_samples,224,224,3),dtype="float32")
    mask = np.zeros(shape=(num_samples,224,224,1),dtype="float32")
    for idx,video_path in enumerate(video_paths):
        temp_image = np.zeros(shape=(2,224,224,3),dtype="float32")
        temp_mask = np.zeros(shape=(2,224,224,1),dtype="float32")
        x1,x2 = yield_segmentation(video_path)
        temp_image[0,:,:,:] = x1[0]
        temp_mask[0,:,:] = np.expand_dims(x1[1],axis=-1)
        temp_image[1,:,:,:] = x2[0]
        temp_mask[1,:,:] = np.expand_dims(x2[1],axis=-1)
        image[2*idx:(2*idx)+2,] = temp_image
        mask[2*idx:(2*idx)+2,] = temp_mask
    return image,mask

class PrepareImagesGen(tf.keras.utils.Sequence):
    def __init__(self,df,batch_size):
        self.df = df.copy()
        self.batch_size = batch_size
        self.input_size = image_size
        self.n = len(self.df)

    def on_epoch_end(self):
        pass

    def __getitem__(self,index):
        batches = self.df[(index*self.batch_size):((index+1)*self.batch_size)]
        X,y = prepare_data(batches,path)
        return X,y

    def __len__(self):
        return self.n//self.batch_size

train_gen = PrepareImagesGen(metadata.loc[metadata["Split"] == "TRAIN",:],batch_size=batch_size)
val_gen = PrepareImagesGen(metadata.loc[metadata["Split"] == "VAL",:],batch_size=batch_size)
checkpoint = keras.callbacks.ModelCheckpoint(filepath="models/segmenter.{epoch:02d}-{val_loss:.2f}.hdf5",save_weights_only=True,save_best_only=False)
scheduler = tf.keras.callbacks.LearningRateScheduler(tf.keras.optimizers.schedules.CosineDecay(learning_rate,50),verbose=0)
model = kt.BayesianOptimization(DeeplabV3Plus1,objective=kt.Objective("val_dice_coef", direction="max"),max_trials=21,seed=42,directory="models/")
history = model.search(train_gen,epochs=epochs,callbacks=[checkpoint,scheduler],validation_data=val_gen)
besthp = model.get_best_hyperparameters()[0]
print(besthp)

image = train_gen.__getitem__(0)
p = network_model.predict(image[0])
#plt.imshow(np.argmax(p[0],axis=2))
plt.imshow((image[1][0]*5)+np.argmax(p[0],axis=2,keepdims=True))

def convolution_block(
    block_input,
    num_filters=256,
    kernel_size=3,
    dilation_rate=1,
    padding="same",
    use_bias=False,
):
    x = layers.Conv2D(
        num_filters,
        kernel_size=kernel_size,
        dilation_rate=dilation_rate,
        padding="same",
        use_bias=use_bias,
        kernel_initializer=keras.initializers.HeNormal(),
    )(block_input)
    x = layers.BatchNormalization()(x)
    return tf.nn.relu(x)


def DilatedSpatialPyramidPooling(dspp_input, i):
    dims = dspp_input.shape
    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)
    x = convolution_block(x, kernel_size=1, use_bias=True)
    out_pool = layers.UpSampling2D(
        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation="bilinear",
    )(x)

    dilation_rate = i # 2 to 12 possibility

    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)
    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=dilation_rate)
    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=dilation_rate*2)
    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=dilation_rate*3)

    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])
    output = convolution_block(x, kernel_size=1)
    return output
def DeeplabV3Plus1(i):
    image_size = 224
    num_classes = 2
    model_input = keras.Input(shape=(image_size, image_size, 3))
    resnet50 = tf.keras.applications.ResNet50(
        weights="imagenet", include_top=False, input_tensor=model_input
    )
    #trainable_layers = hp.Int("trainable_layers",min_value=0,max_value=len(resnet50.layers))
    for idx,layer in enumerate(reversed(resnet50.layers)):
        #if idx == trainable_layers:
            #break
        layer.trainable = True
    x = resnet50.get_layer("conv3_block3_2_relu").output
    x = DilatedSpatialPyramidPooling(x, i)

    input_a = layers.UpSampling2D(
        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),
        interpolation="bilinear",
    )(x)
    input_b = resnet50.get_layer("conv2_block3_2_relu").output
    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)

    x = layers.Concatenate(axis=-1)([input_a, input_b])
    x = convolution_block(x)
    x = convolution_block(x)
    x = layers.UpSampling2D(
        size=(image_size // x.shape[1], image_size // x.shape[2]),
        interpolation="bilinear",
    )(x)
    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding="same")(x)
    model = keras.Model(inputs=model_input, outputs=model_output)
    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,epsilon=1e-8),metrics=["accuracy",dice_coef])
    return model

train_gen = PrepareImagesGen(metadata.loc[metadata["Split"] == "TRAIN",:],batch_size=batch_size)

images = [train_gen.__getitem__(i) for i in range(4)]

for i in range(3,7):
  model = DeeplabV3Plus1(i)
  model.load_weights('SegModels/segmenter.06-0.04.hdf5')
  j = 0
  print(i)
  for image in images:
    print(j, model.evaluate(x=image[0],y=image[1]),sep='\n')
    j += 1
  print('------------------')

import matplotlib.pyplot as plt
from tqdm import tqdm as tqdm

def save_overlay_as_pdf(image, segmentation, filename):
    # Create a binary mask from the segmentation
    binary_mask = np.argmax(segmentation, axis=-1)

    # Create a color mask with the segmentation in blue, normalized
    color_mask = np.zeros_like(image)
    color_mask[binary_mask == 1] = [0, 0, 1] # Blue color, normalized

    # Overlay the color mask on the original image with 75% opacity
    overlayed_image = cv2.addWeighted(image, 0.25, color_mask, 0.75, 0) # 75% opacity

    # Plot and save as PDF
    #plt.tight_layout()
    plt.imshow(overlayed_image)
    plt.axis('off') # Remove axis
    #plt.tight_layout()
    plt.savefig(filename, bbox_inches='tight', pad_inches=0.0, format='pdf')
    plt.close()



# Assuming you have a test generator or some images loaded
test_gen = PrepareImagesGen(metadata.loc[metadata["Split"] == "TEST",:], batch_size=10)

# Load the model
model = DeeplabV3Plus1(4)
model.load_weights('SegModels/segmenter.06-0.04.hdf5')

# Get a batch of images and segmentations
images, _ = test_gen.__getitem__(0)

# Predict segmentations
segmentations = model.predict(images)

# Overlay segmentations and save as PDFs
for i in tqdm(range(10)):
    save_overlay_as_pdf(images[i], segmentations[i], f'segmentation_{i}.pdf')